{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "colab": {
      "name": "“Word Embeddings.ipynb”的副本",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rosefinch-Midsummer/Awesome-Colab/blob/master/NLP/Word_Embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALGAR7f_GdbK",
        "colab_type": "text"
      },
      "source": [
        "# GloVe Word Embeddings Demo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Td2GCIHxGdbS",
        "colab_type": "text"
      },
      "source": [
        "This demo was part of a presentation for [this word embeddings workshop](https://www.eventbrite.com/e/practical-ai-for-female-engineers-product-managers-and-designers-tickets-34805104003) and a talk at [the Demystifying AI conference](https://www.eventbrite.com/e/demystifying-deep-learning-ai-tickets-34351888423).  It is not necessary to download the demo to be able to follow along and enjoy the workshop.\n",
        "\n",
        "It is available on Github at https://github.com/fastai/word-embeddings-workshop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxPtSHeIGdbU",
        "colab_type": "text"
      },
      "source": [
        "## Loading our data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QZ88FKCGdbW",
        "colab_type": "text"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGLtRewfGdbY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Standard Imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import pickle\n",
        "import re\n",
        "import json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tN5nxR9JGdbi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.set_printoptions(precision=4, suppress=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLNWXJzjGdbo",
        "colab_type": "text"
      },
      "source": [
        "The dataset is available at http://files.fast.ai/models/glove/6B.100d.tgz\n",
        "To download and unzip the files from the command line, you can run:\n",
        "\n",
        "    wget http://files.fast.ai/models/glove_50_glove_100.tgz \n",
        "    tar xvzf glove_50_glove_100.tgz"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTH_KYtpGuDV",
        "colab_type": "code",
        "outputId": "30ab59cb-dc41-4527-a434-4cf961a48e27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "!wget http://files.fast.ai/models/glove_50_glove_100.tgz \n",
        "!tar xvzf glove_50_glove_100.tgz"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-23 06:11:52--  http://files.fast.ai/models/glove_50_glove_100.tgz\n",
            "Resolving files.fast.ai (files.fast.ai)... 67.205.15.147\n",
            "Connecting to files.fast.ai (files.fast.ai)|67.205.15.147|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 225083583 (215M) [application/x-gtar-compressed]\n",
            "Saving to: ‘glove_50_glove_100.tgz’\n",
            "\n",
            "glove_50_glove_100. 100%[===================>] 214.66M  34.4MB/s    in 6.7s    \n",
            "\n",
            "2019-12-23 06:11:59 (31.8 MB/s) - ‘glove_50_glove_100.tgz’ saved [225083583/225083583]\n",
            "\n",
            "glove_vectors_100d.npy\n",
            "glove_vectors_50d.npy\n",
            "words.txt\n",
            "wordsidx.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJ0L2K4VGdbq",
        "colab_type": "text"
      },
      "source": [
        "You will need to update the path below to be accurate for where you are storing the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WJLAOQSGdbs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vecs = np.load(\"glove_vectors_100d.npy\")\n",
        "vecs50 = np.load(\"glove_vectors_50d.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBsZ_3FTGdby",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('words.txt') as f:\n",
        "    content = f.readlines()\n",
        "words = [x.strip() for x in content] "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsIsSpdmGdb4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wordidx = json.load(open('wordsidx.txt'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6TNfmcRGdb_",
        "colab_type": "text"
      },
      "source": [
        "### What the data looks like"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j68AhCNFGdcB",
        "colab_type": "text"
      },
      "source": [
        "Let's see what our data looks like:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaTuSKxtGdcD",
        "colab_type": "code",
        "outputId": "b37c9c26-e908-4b8f-e7ba-23535d1c49e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(words)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "400000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHGJz-vyGdcN",
        "colab_type": "code",
        "outputId": "aaca8950-07e7-4201-dd9d-1006a2d299ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "words[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the', ',', '.', 'of', 'to', 'and', 'in', 'a', '\"', \"'s\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQxBn0TOGdcT",
        "colab_type": "code",
        "outputId": "0a69f26c-977e-4084-a7ef-2fcda6304215",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "words[600:610]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['together',\n",
              " 'congress',\n",
              " 'index',\n",
              " 'australia',\n",
              " 'results',\n",
              " 'hard',\n",
              " 'hours',\n",
              " 'land',\n",
              " 'action',\n",
              " 'higher']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEkXxvmIGdcZ",
        "colab_type": "text"
      },
      "source": [
        "wordidx allows us to look up a word in order to find out it's index:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXLs0n7oGdcc",
        "colab_type": "code",
        "outputId": "00b2e19c-c800-49f7-f697-b911a6644e14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "type(wordidx)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aUiEkTzGdcj",
        "colab_type": "code",
        "outputId": "403ae986-87be-47a9-897b-b89a82787f87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "wordidx['feminist']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11853"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fw5F12DKGdcq",
        "colab_type": "code",
        "outputId": "1d350e41-26ae-4563-84d2-1c6f2d1ae0f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "words[11853]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'feminist'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqb0b4tuGdcw",
        "colab_type": "text"
      },
      "source": [
        "## Words as vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCw4yurZGdcy",
        "colab_type": "text"
      },
      "source": [
        "The word \"intelligence\" is represented by the 100 dimensional vector:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZWPeSLlGdc0",
        "colab_type": "code",
        "outputId": "e59265ec-fa01-48e0-c663-d7dd2f3bff5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "type(vecs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bxclzs_JGdc6",
        "colab_type": "code",
        "outputId": "f4cde900-5075-4af5-cb52-31c567b1e469",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "vecs[11853]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.296 ,  0.7626, -0.9866,  0.3776,  0.3194,  0.8286, -0.1686,\n",
              "       -1.4558,  0.1965,  0.3854, -0.3348, -0.6503, -0.2528, -0.11  ,\n",
              "       -0.1545,  0.5354, -0.4527, -0.0516,  0.1312,  0.0744,  0.5001,\n",
              "        0.2151,  0.0688,  0.4347,  0.261 , -0.0371,  0.1385, -1.518 ,\n",
              "        0.0641,  0.149 , -0.0314,  0.5038,  0.2839,  0.3457, -0.4411,\n",
              "       -0.3459, -0.2118,  0.5651, -0.088 , -0.0438, -1.2228,  0.6039,\n",
              "       -0.23  ,  0.2287, -0.2695, -0.9398,  0.2376,  0.3302, -0.2422,\n",
              "        0.6359,  0.1347,  0.5542,  0.1432,  0.2861,  0.0216, -0.7437,\n",
              "        0.3508,  0.362 ,  0.5566,  0.3403,  0.3613,  0.5185, -0.5437,\n",
              "       -0.285 ,  1.1831, -0.1192,  0.2473,  0.0614,  0.4436, -0.244 ,\n",
              "        0.2016,  0.5143, -0.4695, -0.0974, -0.9836, -0.3594,  0.3903,\n",
              "       -0.517 , -0.1659, -1.2132, -1.3228,  0.0578,  0.7022,  0.3492,\n",
              "       -0.9103, -0.381 , -0.1545,  0.4467, -0.009 , -0.9838,  1.0114,\n",
              "       -0.227 ,  0.2697,  0.1566,  0.5613,  0.1175, -0.5755, -0.6324,\n",
              "        0.1052,  1.2465], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4iGBe8tGddB",
        "colab_type": "text"
      },
      "source": [
        "This lets us do some useful calculations. For instance, we can see how far apart two words are using a distance metric:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ya3qyuFmGddD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.spatial.distance import cosine as dist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smJH45izGddK",
        "colab_type": "text"
      },
      "source": [
        "Smaller numbers mean two words are closer together, larger numbers mean they are further apart."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VS_zvew_GddM",
        "colab_type": "text"
      },
      "source": [
        "The distance between similar words is low:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8aBfee8GddO",
        "colab_type": "code",
        "outputId": "f84cf937-f274-4c71-c145-bb9af6935074",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "dist(vecs[wordidx[\"puppy\"]], vecs[wordidx[\"dog\"]])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.27636247873306274"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-MtRuLyGddU",
        "colab_type": "code",
        "outputId": "a8ad0d86-7b84-4e01-abcf-ade8c6b3fbbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "dist(vecs[wordidx[\"queen\"]], vecs[wordidx[\"princess\"]])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.20527541637420654"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "hF5jXHQlGddh",
        "colab_type": "text"
      },
      "source": [
        "And the distance between unrelated words is high:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyRP5tGfGddj",
        "colab_type": "code",
        "outputId": "37b20ad8-1581-4fa9-b37e-a5339de5b667",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "dist(vecs[wordidx[\"celebrity\"]], vecs[wordidx[\"dusty\"]])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9883578838780522"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMmC7T9VGddt",
        "colab_type": "code",
        "outputId": "2081dd22-5c88-4204-8813-dc0de0953a07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "dist(vecs[wordidx[\"kitten\"]], vecs[wordidx[\"airplane\"]])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8729851841926575"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWWWkUUxGddy",
        "colab_type": "code",
        "outputId": "8082c4aa-5f4f-444a-ab8f-41bd7bcd3b80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "dist(vecs[wordidx[\"avalanche\"]], vecs[wordidx[\"antique\"]])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9621107056736946"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRqEXaobGdd4",
        "colab_type": "text"
      },
      "source": [
        "### Bias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCaE3dXUGdd6",
        "colab_type": "text"
      },
      "source": [
        "There is a lot of opportunity for bias:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikz4SiSWGdd8",
        "colab_type": "code",
        "outputId": "7f6c1b8d-69c5-49f4-fd4e-bcfe940df104",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "dist(vecs[wordidx[\"man\"]], vecs[wordidx[\"genius\"]])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5098515152931213"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRO_o29gGdeE",
        "colab_type": "code",
        "outputId": "0b611aeb-fdda-456c-aeb1-a4cfc4007a9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "dist(vecs[wordidx[\"woman\"]], vecs[wordidx[\"genius\"]])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.689783364534378"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jH3aRuL2GdeJ",
        "colab_type": "text"
      },
      "source": [
        "Not all pairs are stereotyped:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrS6jj4fGdeL",
        "colab_type": "code",
        "outputId": "0f32530e-1df9-40da-c4f4-74fb3fbf4de7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "dist(vecs[wordidx[\"man\"]], vecs[wordidx[\"emotional\"]])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5595748424530029"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Yuk8f-3GdeQ",
        "colab_type": "code",
        "outputId": "ef153e50-7774-469e-bc22-23cc004808da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "dist(vecs[wordidx[\"woman\"]], vecs[wordidx[\"emotional\"]])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6257205307483673"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wW30jtrMGdeW",
        "colab_type": "text"
      },
      "source": [
        "I just checked the distance between pairs of words, because this is a quick and simple way to illustrate the concept.  It is also a very **noisy** approach, and **researchers approach this problem in more systematic ways**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5d0m1Qr-GdeY",
        "colab_type": "text"
      },
      "source": [
        "## Visualizing the words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVN6VlbrGdeZ",
        "colab_type": "text"
      },
      "source": [
        "We will use [Plotly](https://plot.ly/), a Python library to make interactive graphs (note: everything below is done with the free, offline version of Plotly)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "M92kXWSXGdeb",
        "colab_type": "text"
      },
      "source": [
        "### Methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "bz0sxwDzGded",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import plotly\n",
        "import plotly.graph_objs as go\n",
        "from plotly.offline import iplot\n",
        "from IPython.display import IFrame"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzhFTq7Zf0mc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def enable_plotly_in_cell():\n",
        "  import IPython\n",
        "  from plotly.offline import init_notebook_mode\n",
        "  display(IPython.core.display.HTML('''<script src=\"/static/components/requirejs/require.js\"></script>'''))\n",
        "  init_notebook_mode(connected=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "NiNNVC8fGdei",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plotly_3d(Y, cat_labels):\n",
        "    trace_dict = {}\n",
        "    for i, label in enumerate(cat_labels):\n",
        "        trace_dict[i] = go.Scatter3d(\n",
        "            x=Y[i*5:(i+1)*5, 0],\n",
        "            y=Y[i*5:(i+1)*5, 1],\n",
        "            z=Y[i*5:(i+1)*5, 2],\n",
        "            mode='markers',\n",
        "            marker=dict(\n",
        "                size=8,\n",
        "                line=dict(\n",
        "                    color='rgba('+ str(i*40) + ',' + str(i*40) + ',' + str(i*40) + ', 0.14)',\n",
        "                    width=0.5\n",
        "                ),\n",
        "                opacity=0.8\n",
        "            ),\n",
        "            text = my_words[i*5:(i+1)*5],\n",
        "            name = label\n",
        "        )\n",
        "\n",
        "    data = [item for item in trace_dict.values()]\n",
        "    layout = go.Layout(\n",
        "        margin=dict(\n",
        "            l=0,\n",
        "            r=0,\n",
        "            b=0,\n",
        "            t=0\n",
        "        )\n",
        "    )\n",
        "\n",
        "    plotly.offline.plot({\n",
        "        \"data\": data,\n",
        "        \"layout\": layout\n",
        "    })"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "OSONcNgnGden",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plotly_2d(Y, cat_labels):\n",
        "    trace_dict = {}\n",
        "    for i, label in enumerate(cat_labels):\n",
        "        trace_dict[i] = go.Scatter(\n",
        "            x=Y[i*5:(i+1)*5, 0],\n",
        "            y=Y[i*5:(i+1)*5, 1],\n",
        "            mode='markers',\n",
        "            marker=dict(\n",
        "                size=8,\n",
        "                line=dict(\n",
        "                    color='rgba('+ str(i*40) + ',' + str(i*40) + ',' + str(i*40) + ', 0.14)',\n",
        "                    width=0.5\n",
        "                ),\n",
        "                opacity=0.8\n",
        "            ),\n",
        "            text = my_words[i*5:(i+1)*5],\n",
        "            name = label\n",
        "        )\n",
        "\n",
        "    data = [item for item in trace_dict.values()]\n",
        "    layout = go.Layout(\n",
        "        margin=dict(\n",
        "            l=0,\n",
        "            r=0,\n",
        "            b=0,\n",
        "            t=0\n",
        "        )\n",
        "    )\n",
        "\n",
        "    plotly.offline.plot({\n",
        "        \"data\": data,\n",
        "        \"layout\": layout\n",
        "    })"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrvAP1xyGdet",
        "colab_type": "text"
      },
      "source": [
        "### Preparing the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZhKeXMnGdew",
        "colab_type": "text"
      },
      "source": [
        "Let's plot words from a few different categories:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6-rob9KGdey",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "categories = [\n",
        "              \"bugs\", \"music\", \n",
        "              \"pleasant\", \"unpleasant\", \n",
        "              \"science\", \"arts\"\n",
        "             ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fc7UV_h1Gde7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_words = [\n",
        "            \"maggot\", \"flea\", \"tarantula\", \"bedbug\", \"mosquito\", \n",
        "            \"violin\", \"cello\", \"flute\", \"harp\", \"mandolin\",\n",
        "            \"joy\", \"love\", \"peace\", \"pleasure\", \"wonderful\",\n",
        "            \"agony\", \"terrible\", \"horrible\", \"nasty\", \"failure\", \n",
        "            \"physics\", \"chemistry\", \"science\", \"technology\", \"engineering\",\n",
        "            \"poetry\", \"art\", \"literature\", \"dance\", \"symphony\",\n",
        "           ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjCEcY3HGdfE",
        "colab_type": "text"
      },
      "source": [
        "Again, we need to look up the indices of our words using the wordidx dictionary:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5a57bVVdGdfI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = np.array([wordidx[word] for word in my_words])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVg-tllrGdfO",
        "colab_type": "code",
        "outputId": "e105cdb7-8173-4375-e92e-3c77aa377b6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "vecs[X].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLrwZrsNGdfU",
        "colab_type": "text"
      },
      "source": [
        "Now, we will make a set combining our words with the first 10,000 words in our entire set of words (some of the words will already be in there), and create a matrix of their embeddings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qimbLkabGdfV",
        "colab_type": "code",
        "outputId": "499151f7-00f6-4111-8d5f-8db54f7593f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "embeddings = np.concatenate((vecs[X], vecs[:10000,:]), axis=0); embeddings.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10030, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "px5Q6PEKGdfa",
        "colab_type": "text"
      },
      "source": [
        "### Viewing the words in 3D"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9q7rmTRGdfc",
        "colab_type": "text"
      },
      "source": [
        "The words are in 100 dimensions, so we will need a way to reduce them to 3 dimensions so that we can view them.  Two good options are T-SNE or PCA.  The main idea is to find a meaningful way to go from 100 dimensions to 3 dimensions (while keeping a similar notion of what is close to what).\n",
        "\n",
        "You would typically just use one of these (T-SNE or PCA).  I've included both if you're interested."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "jJUZB5L6Gdfe",
        "colab_type": "text"
      },
      "source": [
        "#### TSNE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "7caxjHAoGdff",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import manifold"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "CJfNeT4GGdfm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tsne = manifold.TSNE(n_components=3, init='pca', random_state=0)\n",
        "#Y = tsne.fit_transform(subset)\n",
        "Y = tsne.fit_transform(embeddings)\n",
        "plotly_3d(Y, categories)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "b9sgI_nFGdfv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IFrame('temp-plot.html', width=600, height=400)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6GnhCjdGdf2",
        "colab_type": "text"
      },
      "source": [
        "#### PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbec76KZGdf4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import decomposition"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teKcuHvWGdf9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pca = decomposition.PCA(n_components=3).fit(embeddings.T)\n",
        "#pca = decomposition.PCA(n_components=3).fit(subset.T)\n",
        "components = pca.components_\n",
        "plotly_3d(components.T[:len(my_words),:], categories)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "-lp9oG-XGdgC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IFrame('temp-plot.html', width=600, height=400)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdib1H75GdgI",
        "colab_type": "text"
      },
      "source": [
        "## Nearest Neighbors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsiAimNIGdgJ",
        "colab_type": "text"
      },
      "source": [
        "We can also see what words are close to a given word."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZMNSGQmGdgL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.neighbors import NearestNeighbors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFVXznOWGdgR",
        "colab_type": "text"
      },
      "source": [
        "Nearest Neighbors is an algorithm that finds the points closest to a given point."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTMfKp-ZGdgS",
        "colab_type": "code",
        "outputId": "deccb47f-f484-4992-94c6-3b2cbf7db605",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "neigh = NearestNeighbors(n_neighbors=10, radius=0.5, metric='cosine', algorithm='brute')\n",
        "neigh.fit(vecs) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NearestNeighbors(algorithm='brute', leaf_size=30, metric='cosine',\n",
              "                 metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n",
              "                 radius=0.5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "9REBqujPGdgc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "distances, indices = neigh.kneighbors([vecs[wordidx[\"feminist\"]]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBGC_BakGdgh",
        "colab_type": "code",
        "outputId": "8d1199d2-1ab8-4d3a-e678-ca8060defb48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "[(words[int(ind)], dist) for ind, dist in zip(list(indices[0]), list(distances[0]))]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('feminist', 1.1920929e-07),\n",
              " ('feminism', 0.24721634),\n",
              " ('feminists', 0.28110862),\n",
              " ('activism', 0.34637702),\n",
              " ('activist', 0.36203873),\n",
              " ('lesbian', 0.3641898),\n",
              " ('humanist', 0.37725556),\n",
              " ('modernist', 0.3795184),\n",
              " ('left-wing', 0.37973535),\n",
              " ('postmodern', 0.38574135)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MScD-d-PGdgo",
        "colab_type": "text"
      },
      "source": [
        "We can take this a step further, and add two words together.  What is the result?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QYnbMDZGdgq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_vec = vecs[wordidx[\"artificial\"]] + vecs[wordidx[\"intelligence\"]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AluQZBT4Gdgv",
        "colab_type": "code",
        "outputId": "b2de1a0a-840c-4bda-9998-4b040e88d561",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "new_vec"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.0345, -0.1185,  0.746 ,  0.3256,  0.3256, -1.4699, -0.8715,\n",
              "       -0.9421,  0.0679,  0.922 ,  0.6811, -0.3729,  1.0969,  0.7196,\n",
              "        1.3515,  1.2493,  0.6621,  0.1901, -0.2707, -0.0444, -1.232 ,\n",
              "        0.1744,  0.7577, -0.9177, -1.2184,  0.6959, -0.1966, -0.415 ,\n",
              "       -0.3358,  0.5452,  0.589 , -0.0299, -0.9744, -0.8937,  0.2283,\n",
              "       -0.2092, -1.3795,  1.7811,  0.2269,  0.47  , -0.3045, -0.1573,\n",
              "       -0.478 ,  0.3071,  0.4202, -0.4434,  0.1602,  0.1443, -0.9528,\n",
              "       -0.5565,  0.7537,  0.182 ,  1.4008,  1.8967,  0.595 , -3.0072,\n",
              "        0.6811, -0.2557,  2.0217,  0.7825,  0.4251,  1.3615,  0.5902,\n",
              "       -0.1312,  0.9344, -0.5377, -0.3988, -0.6415,  0.6527,  0.5117,\n",
              "        0.7315,  0.1396,  0.3785, -0.6403, -0.094 ,  0.1076,  0.6197,\n",
              "        0.2537, -1.4346,  1.169 ,  1.6931,  0.1458, -0.5981,  0.8195,\n",
              "       -3.1903,  1.2429,  2.1481,  1.6004,  0.2014, -0.2121,  0.3698,\n",
              "       -0.001 , -0.628 ,  0.2869,  0.3119, -0.1093, -0.6341, -1.7804,\n",
              "        0.5857,  0.3702], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xu98bu7dGdg0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "distances, indices = neigh.kneighbors([new_vec])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3630X7WrGdhL",
        "colab_type": "code",
        "outputId": "a92a77de-18d4-4602-94b8-6b34623db35f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "[(words[int(ind)], dist) for ind, dist in zip(list(indices[0]), list(distances[0]))]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('intelligence', 0.18831605),\n",
              " ('artificial', 0.25617576),\n",
              " ('information', 0.3256532),\n",
              " ('knowledge', 0.33641893),\n",
              " ('secret', 0.36480355),\n",
              " ('human', 0.3672669),\n",
              " ('biological', 0.37090683),\n",
              " ('using', 0.3773631),\n",
              " ('scientific', 0.385139),\n",
              " ('communication', 0.38691515)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oph82ZfPGdhQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "distances, indices = neigh.kneighbors([vecs[wordidx[\"king\"]]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPSIziCdGdhT",
        "colab_type": "code",
        "outputId": "3e5907f8-9d26-4898-9767-87b9717a2f46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "[(words[int(ind)], dist) for ind, dist in zip(list(indices[0]), list(distances[0]))]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('king', 0.0),\n",
              " ('prince', 0.23176706),\n",
              " ('queen', 0.24923098),\n",
              " ('son', 0.2979113),\n",
              " ('brother', 0.30142248),\n",
              " ('monarch', 0.30221093),\n",
              " ('throne', 0.30800098),\n",
              " ('kingdom', 0.31885898),\n",
              " ('father', 0.3197971),\n",
              " ('emperor', 0.32871425)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5DGPaXVGdhX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_vec = vecs[wordidx[\"king\"]] - vecs[wordidx[\"he\"]] + vecs[wordidx[\"she\"]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eyZgxJbGdhc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "distances, indices = neigh.kneighbors([new_vec])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDbzmU82Gdhk",
        "colab_type": "code",
        "outputId": "2fa470a5-d6a2-4652-c975-b80cb7f4db09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "[(words[int(ind)], dist) for ind, dist in zip(list(indices[0]), list(distances[0]))]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('king', 0.13275808),\n",
              " ('queen', 0.16259885),\n",
              " ('princess', 0.24821734),\n",
              " ('daughter', 0.29121184),\n",
              " ('prince', 0.29464376),\n",
              " ('elizabeth', 0.29630506),\n",
              " ('mother', 0.3091293),\n",
              " ('sister', 0.31979597),\n",
              " ('father', 0.34473372),\n",
              " ('throne', 0.34474844)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFGf6dW0Gdhz",
        "colab_type": "code",
        "outputId": "fd2507a8-6add-4406-d661-07a213e9d405",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "wordidx[\"programmer\"]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19226"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kpgz9eiSmS0_",
        "colab_type": "code",
        "outputId": "eba64563-b397-41ab-e63e-6bd51ac2343a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "wordidx[\"student\"]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1283"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODIkdXm_GdiL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "distances, indices = neigh.kneighbors([vecs[wordidx[\"programmer\"]]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69mskE6yGdiW",
        "colab_type": "text"
      },
      "source": [
        "Closest words to \"programmer\":"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfKthI6AGdiX",
        "colab_type": "code",
        "outputId": "8dfbc979-c069-48f8-8f7f-cfabd4b59a50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "[(words[int(ind)], dist) for ind, dist in zip(list(indices[0]), list(distances[0]))]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('programmer', 1.1920929e-07),\n",
              " ('programmers', 0.32259798),\n",
              " ('animator', 0.36951023),\n",
              " ('software', 0.38250887),\n",
              " ('computer', 0.40600342),\n",
              " ('technician', 0.41406858),\n",
              " ('engineer', 0.4303757),\n",
              " ('user', 0.4356534),\n",
              " ('translator', 0.43721008),\n",
              " ('linguist', 0.44948018)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EA7ypnwRGdic",
        "colab_type": "text"
      },
      "source": [
        "Feminine version of \"programmer\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mD33_QrGdie",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_vec = vecs[wordidx[\"programmer\"]] - vecs[wordidx[\"he\"]] + vecs[wordidx[\"she\"]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sQyyBX4Gdii",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "distances, indices = neigh.kneighbors([new_vec])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbParHWlGdip",
        "colab_type": "code",
        "outputId": "eabe2e9f-a1c4-4b0f-c9d6-8d3ef960172e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "[(words[int(ind)], dist) for ind, dist in zip(list(indices[0]), list(distances[0]))]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('programmer', 0.1950342),\n",
              " ('stylist', 0.42715955),\n",
              " ('animator', 0.4820645),\n",
              " ('programmers', 0.48337305),\n",
              " ('choreographer', 0.4862678),\n",
              " ('technician', 0.48628056),\n",
              " ('designer', 0.48710012),\n",
              " ('prodigy', 0.49118334),\n",
              " ('lets', 0.49730027),\n",
              " ('screenwriter', 0.49754214)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoC2wpbmGdi2",
        "colab_type": "text"
      },
      "source": [
        "Masculine version of \"programmer\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ga0HkmOlGdi4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_vec = vecs[wordidx[\"programmer\"]] - vecs[wordidx[\"she\"]] + vecs[wordidx[\"he\"]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbTQ6gYqGdi8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "distances, indices = neigh.kneighbors([new_vec])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8Gzey-KGdjB",
        "colab_type": "code",
        "outputId": "8b1f34f5-3503-4aec-d19a-0b46298d5fb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "[(words[int(ind)], dist) for ind, dist in zip(list(indices[0]), list(distances[0]))]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('programmer', 0.17419636),\n",
              " ('programmers', 0.4133587),\n",
              " ('engineer', 0.46376413),\n",
              " ('compiler', 0.467317),\n",
              " ('software', 0.4681465),\n",
              " ('animator', 0.4892366),\n",
              " ('computer', 0.5046158),\n",
              " ('mechanic', 0.5150068),\n",
              " ('setup', 0.51882535),\n",
              " ('developer', 0.51953185)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmDoB4dMGdjK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "distances, indices = neigh.kneighbors([vecs[wordidx[\"doctor\"]]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "TSEYfHSlGdjN",
        "colab_type": "code",
        "outputId": "17af5671-a160-4cf6-828e-5a10b85caad1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "[(words[int(ind)], dist) for ind, dist in zip(list(indices[0]), list(distances[0]))]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('doctor', 5.9604645e-08),\n",
              " ('physician', 0.23267603),\n",
              " ('nurse', 0.24784917),\n",
              " ('dr.', 0.28248066),\n",
              " ('doctors', 0.29191148),\n",
              " ('patient', 0.29258162),\n",
              " ('medical', 0.30040073),\n",
              " ('surgeon', 0.30946612),\n",
              " ('hospital', 0.30990708),\n",
              " ('psychiatrist', 0.3410902)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pE4uS3RGdjU",
        "colab_type": "text"
      },
      "source": [
        "Feminine version of doctor:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAjzBAU4GdjW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_vec = vecs[wordidx[\"doctor\"]] - vecs[wordidx[\"he\"]] + vecs[wordidx[\"she\"]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxzTfiPZGdjb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "distances, indices = neigh.kneighbors([new_vec])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "1FiOq0nXGdjh",
        "colab_type": "code",
        "outputId": "2a87d349-3758-47f4-b6c8-e9c28213df9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "[(words[int(ind)], dist) for ind, dist in zip(list(indices[0]), list(distances[0]))]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('doctor', 0.13456273),\n",
              " ('nurse', 0.22582495),\n",
              " ('mother', 0.27610385),\n",
              " ('woman', 0.29901665),\n",
              " ('pregnant', 0.32096934),\n",
              " ('girl', 0.3324105),\n",
              " ('patient', 0.34357917),\n",
              " ('she', 0.35723114),\n",
              " ('child', 0.3631252),\n",
              " ('herself', 0.36338794)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10eNbiPJGdjp",
        "colab_type": "text"
      },
      "source": [
        "Masculine version of doctor:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbQK6vyoGdjq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_vec = vecs[wordidx[\"doctor\"]] - vecs[wordidx[\"she\"]] + vecs[wordidx[\"he\"]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyFaXsETGdjt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "distances, indices = neigh.kneighbors([new_vec])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "ckWYXBx4Gdjy",
        "colab_type": "code",
        "outputId": "00606b2d-01bf-4406-9003-e1173cf8ec3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "[(words[int(ind)], dist) for ind, dist in zip(list(indices[0]), list(distances[0]))]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('doctor', 0.15277696),\n",
              " ('physician', 0.27226865),\n",
              " ('medical', 0.37674332),\n",
              " ('he', 0.37695646),\n",
              " ('doctors', 0.38290107),\n",
              " ('dr.', 0.38466895),\n",
              " ('surgeon', 0.39124882),\n",
              " ('him', 0.40270942),\n",
              " ('hospital', 0.42226428),\n",
              " ('himself', 0.42476082)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTRhP3SsGdj6",
        "colab_type": "text"
      },
      "source": [
        "## Bias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyBXoEObGdj9",
        "colab_type": "text"
      },
      "source": [
        "Again, just looking at individual words is a **noisy** approach (I'm using it as a simple illustration).  [Researchers from Princeton and University of Bath](https://www.princeton.edu/~aylinc/papers/caliskan-islam_semantics.pdf) use **small baskets of terms** to represent concepts.  They first confirmed that flowers are more pleasant than insects, and musical instruments are more pleasant from weapons.\n",
        "\n",
        "They then found that European American names are \"more pleasant\" than African American names, as captured by how close the word vectors are (as embedded by GloVe, which is a library from Stanford, along the same lines as Word2Vec).\n",
        "\n",
        "    We show for the first time that if AI is to exploit via our language the vast \n",
        "    knowledge that culture has compiled, it will inevitably inherit human-like \n",
        "    prejudices. In other words, if AI learns enough about the properties of language \n",
        "    to be able to understand and produce it, it also acquires cultural associations \n",
        "    that can be offensive, objectionable, or harmful.\n",
        "\n",
        "[Researchers from Boston University and Microsoft Research](https://arxiv.org/pdf/1606.06121.pdf) found the pairs most analogous to *He : She*.  They found gender bias, and also proposed a way to debias the vectors.\n",
        "\n",
        "Rob Speer, CTO of Luminoso, tested for ethnic bias by finding correlations for a list of positive and negative words:\n",
        "\n",
        "    The tests I implemented for ethnic bias are to take a list of words, such as \n",
        "    “white”, “black”, “Asian”, and “Hispanic”, and find which one has the strongest \n",
        "    correlation with each of a list of positive and negative words, such as “cheap”, \n",
        "    “criminal”, “elegant”, and “genius”. I did this again with a fine-grained version \n",
        "    that lists hundreds of words for ethnicities and nationalities, and thus is more \n",
        "    difficult to get a low score on, and again with what may be the trickiest test of \n",
        "    all, comparing words for different religions and spiritual beliefs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzTpre02GdkJ",
        "colab_type": "text"
      },
      "source": [
        "**Ways to address bias**\n",
        "\n",
        "There are a few different approaches:\n",
        "\n",
        "- Debias word embeddings\n",
        "  - [Technique in Bolukbasi, et al.](https://arxiv.org/abs/1606.06121)\n",
        "  - [ConceptNet Numberbatch (Rob Speer)](https://blog.conceptnet.io/2017/04/24/conceptnet-numberbatch-17-04-better-less-stereotyped-word-vectors/)\n",
        "- Argument that “awareness is better than blindness”: debiasing should happen at time of action, not at perception. ([Caliskan-Islam, Bryson, Narayanan](https://www.princeton.edu/~aylinc/papers/caliskan-islam_semantics.pdf))\n",
        "\n",
        "Either way, you need to be on the lookout for bias and have a plan to address it!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s14ZLUKqGdkK",
        "colab_type": "text"
      },
      "source": [
        "If you are interested in the topic of bias in AI, I gave a workshop [you can watch here](https://www.youtube.com/watch?v=25nC0n9ERq4) that covers this material and goes into more depth about bias."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqLfR3CfGdkM",
        "colab_type": "text"
      },
      "source": [
        "This demo has been adapted (and simplified) from part of Lesson 5 of [Practical Deep Learning for Coders](http://course.fast.ai/index.html)"
      ]
    }
  ]
}