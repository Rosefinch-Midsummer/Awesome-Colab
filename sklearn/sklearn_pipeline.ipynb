{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sklearn-pipeline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rosefinch-Midsummer/Awesome-Colab/blob/master/sklearn/sklearn_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pbeU2jVcI15",
        "colab_type": "text"
      },
      "source": [
        "[docs](https://scikit-learn.org/stable/)\n",
        "\n",
        "[apache-cn-docs](https://sklearn.apachecn.org/)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIKoO55u-D07",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.externals import joblib\n",
        "#save\n",
        "joblib.dump(clf, 'save/clf.pkl')\n",
        "\n",
        "#load\n",
        "clf3=joblib.load('save/clf.pkl')\n",
        "print(clf3.predict(X[0:1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDbxMgmmVwo6",
        "colab_type": "text"
      },
      "source": [
        "# pipeline\n",
        "\n",
        "[Auto Machine Learning笔记 - Pipelines 制作教程](http://codewithzhangyi.com/2018/08/07/Machine%20Learning%E7%AC%94%E8%AE%B0%20-%20Pipelines%20%E5%88%B6%E4%BD%9C%E6%95%99%E7%A8%8B/)\n",
        "\n",
        "征选择、标准化和分类。Pipeline 在这里有多种用途:\n",
        "\n",
        "- 便捷性和封装性 你只要对数据调用 fit和 predict 一次来适配所有的一系列评估器。\n",
        "- 联合的参数选择 你可以一次grid search管道中所有评估器的参数。\n",
        "- 安全性 训练转换器和预测器使用的是相同样本，管道有助于防止来自测试数据的统计数据泄露到交叉验证的训练模型中。\n",
        "\n",
        "管道中的所有评估器，除了最后一个评估器，管道的所有评估器必须是转换器。 (例如，必须有 transform 方法). 最后一个评估器的类型不限（转换器、分类器等等）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgHlmkBZWDKX",
        "colab_type": "code",
        "outputId": "e702c2dd-312d-4681-931f-2de3bdb2ed42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = \"naesaranderzhang\" # username from the json file\n",
        "os.environ['KAGGLE_KEY'] = \"d580334ca87c88ae66a1995d318dca80\" # key from the json file\n",
        "!kaggle competitions download -c spooky-author-identification # api copied from kaggle"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading test.zip to /content\n",
            "  0% 0.00/538k [00:00<?, ?B/s]\n",
            "100% 538k/538k [00:00<00:00, 81.0MB/s]\n",
            "Downloading sample_submission.zip to /content\n",
            "  0% 0.00/29.4k [00:00<?, ?B/s]\n",
            "100% 29.4k/29.4k [00:00<00:00, 27.5MB/s]\n",
            "Downloading train.zip to /content\n",
            "  0% 0.00/1.26M [00:00<?, ?B/s]\n",
            "100% 1.26M/1.26M [00:00<00:00, 81.6MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1viarnaWDcU",
        "colab_type": "code",
        "outputId": "87e2b80e-60d1-49ad-c0a0-f314a5a5e68e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "!unzip train.zip\n",
        "!unzip test.zip\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  train.zip\n",
            "  inflating: train.csv               \n",
            "Archive:  test.zip\n",
            "  inflating: test.csv                \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ensHpWJWDym",
        "colab_type": "code",
        "outputId": "387d8756-db38-4bf4-d5db-11f94ff48cfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "df_train = pd.read_csv('train.csv')\n",
        "\n",
        "df_train.dropna(axis=0)\n",
        "df_train.set_index('id', inplace = True)\n",
        "\n",
        "df_train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>author</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>id26305</th>\n",
              "      <td>This process, however, afforded me no means of...</td>\n",
              "      <td>EAP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id17569</th>\n",
              "      <td>It never once occurred to me that the fumbling...</td>\n",
              "      <td>HPL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id11008</th>\n",
              "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
              "      <td>EAP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id27763</th>\n",
              "      <td>How lovely is spring As we looked from Windsor...</td>\n",
              "      <td>MWS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id12958</th>\n",
              "      <td>Finding nothing else, not even gold, the Super...</td>\n",
              "      <td>HPL</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                      text author\n",
              "id                                                               \n",
              "id26305  This process, however, afforded me no means of...    EAP\n",
              "id17569  It never once occurred to me that the fumbling...    HPL\n",
              "id11008  In his left hand was a gold snuff box, from wh...    EAP\n",
              "id27763  How lovely is spring As we looked from Windsor...    MWS\n",
              "id12958  Finding nothing else, not even gold, the Super...    HPL"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7ULwq1NY2xa",
        "colab_type": "text"
      },
      "source": [
        "文本特征预处理\n",
        "\n",
        "以下为适用于所有文本的数据清洗操作：\n",
        "\n",
        "- 将文本信息去标点符号，且全部用小写字母\n",
        "- 计算文本长度\n",
        "- 计算文本字数\n",
        "- 计算 非停用词 字数\n",
        "- 计算 非停用词单词的 平均长度\n",
        "- 计算逗号数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24Kzzq1LYyDJ",
        "colab_type": "code",
        "outputId": "6a0b5a25-9cd5-4612-8a52-7a4cd750c6aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "nltk.download(\"stopwords\")\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stopWords = set(stopwords.words('english')) # 可能需要手动下载 stopwords\n",
        "\n",
        "#creating a function to encapsulate preprocessing, to mkae it easy to replicate on  submission data\n",
        "def processing(df):\n",
        "    #lowering and removing punctuation\n",
        "    df['processed'] = df['text'].apply(lambda x: re.sub(r'[^\\w\\s]','', x.lower()))\n",
        "    \n",
        "    #numerical feature engineering\n",
        "    #total length of sentence\n",
        "    df['length'] = df['processed'].apply(lambda x: len(x))\n",
        "    #get number of words\n",
        "    df['words'] = df['processed'].apply(lambda x: len(x.split(' ')))\n",
        "    df['words_not_stopword'] = df['processed'].apply(lambda x: len([t for t in x.split(' ') if t not in stopWords]))\n",
        "    #get the average word length\n",
        "    df['avg_word_length'] = df['processed'].apply(lambda x: np.mean([len(t) for t in x.split(' ') if t not in stopWords]) if len([len(t) for t in x.split(' ') if t not in stopWords]) > 0 else 0)\n",
        "    #get the average word length\n",
        "    df['commas'] = df['text'].apply(lambda x: x.count(','))\n",
        "\n",
        "    return(df)\n",
        "\n",
        "df_train= processing(df_train)\n",
        "\n",
        "df_train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>author</th>\n",
              "      <th>processed</th>\n",
              "      <th>length</th>\n",
              "      <th>words</th>\n",
              "      <th>words_not_stopword</th>\n",
              "      <th>avg_word_length</th>\n",
              "      <th>commas</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>id26305</th>\n",
              "      <td>This process, however, afforded me no means of...</td>\n",
              "      <td>EAP</td>\n",
              "      <td>this process however afforded me no means of a...</td>\n",
              "      <td>224</td>\n",
              "      <td>41</td>\n",
              "      <td>21</td>\n",
              "      <td>6.380952</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id17569</th>\n",
              "      <td>It never once occurred to me that the fumbling...</td>\n",
              "      <td>HPL</td>\n",
              "      <td>it never once occurred to me that the fumbling...</td>\n",
              "      <td>70</td>\n",
              "      <td>14</td>\n",
              "      <td>6</td>\n",
              "      <td>6.166667</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id11008</th>\n",
              "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
              "      <td>EAP</td>\n",
              "      <td>in his left hand was a gold snuff box from whi...</td>\n",
              "      <td>195</td>\n",
              "      <td>36</td>\n",
              "      <td>19</td>\n",
              "      <td>5.947368</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id27763</th>\n",
              "      <td>How lovely is spring As we looked from Windsor...</td>\n",
              "      <td>MWS</td>\n",
              "      <td>how lovely is spring as we looked from windsor...</td>\n",
              "      <td>202</td>\n",
              "      <td>34</td>\n",
              "      <td>21</td>\n",
              "      <td>6.476190</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id12958</th>\n",
              "      <td>Finding nothing else, not even gold, the Super...</td>\n",
              "      <td>HPL</td>\n",
              "      <td>finding nothing else not even gold the superin...</td>\n",
              "      <td>170</td>\n",
              "      <td>27</td>\n",
              "      <td>16</td>\n",
              "      <td>7.187500</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                      text  ... commas\n",
              "id                                                          ...       \n",
              "id26305  This process, however, afforded me no means of...  ...      4\n",
              "id17569  It never once occurred to me that the fumbling...  ...      0\n",
              "id11008  In his left hand was a gold snuff box, from wh...  ...      4\n",
              "id27763  How lovely is spring As we looked from Windsor...  ...      3\n",
              "id12958  Finding nothing else, not even gold, the Super...  ...      2\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ps-IsBaraB9u",
        "colab_type": "text"
      },
      "source": [
        "创建 Pipeline\n",
        "\n",
        "拆分训练集和测试集，输入："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDyQ_AVJYx_c",
        "colab_type": "code",
        "outputId": "eed79973-f4a1-4f81-a009-ba23939fc91a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "features= [c for c in df_train.columns.values if c  not in ['id','text','author']]\n",
        "numeric_features= [c for c in df_train.columns.values if c  not in ['id','text','author','processed']]\n",
        "target = 'author'\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_train[features], df_train[target], test_size=0.33, random_state=42)\n",
        "X_train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>processed</th>\n",
              "      <th>length</th>\n",
              "      <th>words</th>\n",
              "      <th>words_not_stopword</th>\n",
              "      <th>avg_word_length</th>\n",
              "      <th>commas</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>id19417</th>\n",
              "      <td>this panorama is indeed glorious and i should ...</td>\n",
              "      <td>91</td>\n",
              "      <td>18</td>\n",
              "      <td>6</td>\n",
              "      <td>6.666667</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id09522</th>\n",
              "      <td>there was a simple natural earnestness about h...</td>\n",
              "      <td>240</td>\n",
              "      <td>44</td>\n",
              "      <td>18</td>\n",
              "      <td>6.277778</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id22732</th>\n",
              "      <td>who are you pray that i duc de lomelette princ...</td>\n",
              "      <td>387</td>\n",
              "      <td>74</td>\n",
              "      <td>38</td>\n",
              "      <td>5.552632</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id10351</th>\n",
              "      <td>he had gone in the carriage to the nearest tow...</td>\n",
              "      <td>118</td>\n",
              "      <td>24</td>\n",
              "      <td>11</td>\n",
              "      <td>5.363636</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id24580</th>\n",
              "      <td>there is no method in their proceedings beyond...</td>\n",
              "      <td>71</td>\n",
              "      <td>13</td>\n",
              "      <td>5</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 processed  ...  commas\n",
              "id                                                          ...        \n",
              "id19417  this panorama is indeed glorious and i should ...  ...       1\n",
              "id09522  there was a simple natural earnestness about h...  ...       4\n",
              "id22732  who are you pray that i duc de lomelette princ...  ...       9\n",
              "id10351  he had gone in the carriage to the nearest tow...  ...       0\n",
              "id24580  there is no method in their proceedings beyond...  ...       1\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jD-rG7MLbNwR",
        "colab_type": "text"
      },
      "source": [
        "接下来是关键步骤。\n",
        "\n",
        "根据特征是否为数值型，创建 两个selector transformers: TextSelector，NumberSelector\n",
        "\n",
        "selector的作用：输入一个column，根据这个selector transformer，输出得到一个新column\n",
        "\n",
        "简单说就是，做 data transformation，收集想要的信息，比如 text length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4KbaI4hYx6g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "class TextSelector(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    Transformer to select a single column from the data frame to perform additional transformations on\n",
        "    Use on text columns in the data\n",
        "    \"\"\"\n",
        "    def __init__(self, key):\n",
        "        self.key = key\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return X[self.key]\n",
        "    \n",
        "class NumberSelector(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    Transformer to select a single column from the data frame to perform additional transformations on\n",
        "    Use on numeric columns in the data\n",
        "    \"\"\"\n",
        "    def __init__(self, key):\n",
        "        self.key = key\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return X[[self.key]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orXSIr-7cdj_",
        "colab_type": "text"
      },
      "source": [
        "先来试一下 TextSelector 好不好用。由小变大，先创建一个mini pipeline，作用是先从数据集中抓取一列数据，再做tf-idf处理并返回结果。\n",
        "\n",
        "创建过程只需传递一个格式如（名称，对象）的元组。括号左边是动作的名称，右边就是选取的列名。所以这个mini pipeline就是两个动作，selecting（选择一列）和tfidf-ing（对这列进行tf-idf处理）。\n",
        "\n",
        "执行pipeline的命令，可以调用 text.fit() 来适应训练集，text.transform() 来应用于训练集，或者text.fit_transform() 来执行两者。\n",
        "\n",
        "由于它是一个文本，它将返回一个稀疏矩阵，输入："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sbo2jcJjcVhf",
        "colab_type": "code",
        "outputId": "8d9166e5-34f9-4085-9d35-65787d600855",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "text = Pipeline([\n",
        "                ('selector', TextSelector(key='processed')),\n",
        "                ('tfidf', TfidfVectorizer( stop_words='english'))\n",
        "            ])\n",
        "\n",
        "text.fit_transform(X_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<13117x21516 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 148061 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FgUWGlkdEbv",
        "colab_type": "text"
      },
      "source": [
        "接下来试一下 NumberSelector 对于数值型的特征处理好不好用，同样也先建立一个mini pipeline来观察效果。\n",
        "\n",
        "这个pipeline操作就定为简单的scaler，一列列的进行数值的StandardScaler。先以 length列为例，仍然是两个步骤，先选列，即length列，再做数值StandardScaler。（StandardScaler是数据预处理的一个常见的数值缩放操作。）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZ4FrTCMcVdq",
        "colab_type": "code",
        "outputId": "057286bd-f2a1-40cb-b669-13b421c01520",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "length =  Pipeline([\n",
        "                ('selector', NumberSelector(key='length')),\n",
        "                ('standard', StandardScaler())\n",
        "            ])\n",
        "\n",
        "length.fit_transform(X_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.50769254],\n",
              "       [ 0.88000324],\n",
              "       [ 2.24907223],\n",
              "       ...,\n",
              "       [-0.46112557],\n",
              "       [-0.14447015],\n",
              "       [-0.39593181]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUybGJcGdhRc",
        "colab_type": "text"
      },
      "source": [
        "根据输出结果可以看出，pipeline返回一个我们想要的数值缩放矩阵。然后把剩下的数值特征列都进行缩放scaler操作。当然这个数据处理操作你可以随意更改成其他可用的。\n",
        "\n",
        "输入："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n89isrxXcVY0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words =  Pipeline([\n",
        "                ('selector', NumberSelector(key='words')),\n",
        "                ('standard', StandardScaler())\n",
        "            ])\n",
        "words_not_stopword =  Pipeline([\n",
        "                ('selector', NumberSelector(key='words_not_stopword')),\n",
        "                ('standard', StandardScaler())\n",
        "            ])\n",
        "avg_word_length =  Pipeline([\n",
        "                ('selector', NumberSelector(key='avg_word_length')),\n",
        "                ('standard', StandardScaler())\n",
        "            ])\n",
        "commas =  Pipeline([\n",
        "                ('selector', NumberSelector(key='commas')),\n",
        "                ('standard', StandardScaler()),\n",
        "            ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFDyg_zcdtOW",
        "colab_type": "text"
      },
      "source": [
        "创建 FeatureUnion\n",
        "\n",
        "pipeline管道可大可小，又大又长又粗的pipeline也是由一个个mini pipelines组成的嘛。\n",
        "\n",
        "接下来使用FeatureUnion来连接上面做好的pipelines，形成一个类似大的pipeline。\n",
        "\n",
        "语法操作还是格式如（名称，对象）的元组。FeatureUnion本身不是pipeline，它只是一个组合，所以需要多写一行代码，将其变为一个大pipeline。然后的事情，你懂的，还是fit，transform，或者fit_transform操作。\n",
        "\n",
        "输入："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeygEKurcVQh",
        "colab_type": "code",
        "outputId": "f38a49c9-3985-49d6-df3d-c50ca788be0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "from sklearn.pipeline import FeatureUnion\n",
        "\n",
        "feats = FeatureUnion([('text', text), \n",
        "                      ('length', length),\n",
        "                      ('words', words),\n",
        "                      ('words_not_stopword', words_not_stopword),\n",
        "                      ('avg_word_length', avg_word_length),\n",
        "                      ('commas', commas)])\n",
        "\n",
        "feature_processing = Pipeline([('feats', feats)])\n",
        "feature_processing.fit_transform(X_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<13117x21521 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 213646 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzWqlDuSeFS5",
        "colab_type": "text"
      },
      "source": [
        "甚至可以在刚刚的大pipeline尾巴上再添加一个分类器，即不仅仅是数据转化，而是增加建模/预测功能。还是原来的套路，写元组，再pipeline一下。\n",
        "\n",
        "可以得到粗糙的 63.8%的分类精度。小试牛刀，不要太在意这些细节~"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVF4tCG9Yxyq",
        "colab_type": "code",
        "outputId": "21102693-4b98-4403-cfbb-404beaa6aa0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('features',feats),\n",
        "    ('classifier', RandomForestClassifier(random_state = 42)),\n",
        "])\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "preds = pipeline.predict(X_test)\n",
        "np.mean(preds == y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6388115134633241"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92BTZ2uJejqd",
        "colab_type": "text"
      },
      "source": [
        "再看 Pipeline\n",
        "\n",
        "现在可以得出的结论就是，pipeline不仅能做数据预处理的流水线，更是能把整个建模套路做成流水线，只需在pipeline的结尾加上一个分类器。接下来将创建一个pipeline，完成上面所有的处理，最后用随机森林分类器。\n",
        "\n",
        "优化 Pipeline\n",
        "\n",
        "利用 Cross Validation 寻找更优的pipeline，就要先观察pipeline的属性，再进行超参数调参。\n",
        "\n",
        "输入："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kr6H4E8zenK_",
        "colab_type": "code",
        "outputId": "e20cbb8d-b9e7-42c8-d20a-43f44cf33fb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "pipeline.get_params().keys()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['memory', 'steps', 'verbose', 'features', 'classifier', 'features__n_jobs', 'features__transformer_list', 'features__transformer_weights', 'features__verbose', 'features__text', 'features__length', 'features__words', 'features__words_not_stopword', 'features__avg_word_length', 'features__commas', 'features__text__memory', 'features__text__steps', 'features__text__verbose', 'features__text__selector', 'features__text__tfidf', 'features__text__selector__key', 'features__text__tfidf__analyzer', 'features__text__tfidf__binary', 'features__text__tfidf__decode_error', 'features__text__tfidf__dtype', 'features__text__tfidf__encoding', 'features__text__tfidf__input', 'features__text__tfidf__lowercase', 'features__text__tfidf__max_df', 'features__text__tfidf__max_features', 'features__text__tfidf__min_df', 'features__text__tfidf__ngram_range', 'features__text__tfidf__norm', 'features__text__tfidf__preprocessor', 'features__text__tfidf__smooth_idf', 'features__text__tfidf__stop_words', 'features__text__tfidf__strip_accents', 'features__text__tfidf__sublinear_tf', 'features__text__tfidf__token_pattern', 'features__text__tfidf__tokenizer', 'features__text__tfidf__use_idf', 'features__text__tfidf__vocabulary', 'features__length__memory', 'features__length__steps', 'features__length__verbose', 'features__length__selector', 'features__length__standard', 'features__length__selector__key', 'features__length__standard__copy', 'features__length__standard__with_mean', 'features__length__standard__with_std', 'features__words__memory', 'features__words__steps', 'features__words__verbose', 'features__words__selector', 'features__words__standard', 'features__words__selector__key', 'features__words__standard__copy', 'features__words__standard__with_mean', 'features__words__standard__with_std', 'features__words_not_stopword__memory', 'features__words_not_stopword__steps', 'features__words_not_stopword__verbose', 'features__words_not_stopword__selector', 'features__words_not_stopword__standard', 'features__words_not_stopword__selector__key', 'features__words_not_stopword__standard__copy', 'features__words_not_stopword__standard__with_mean', 'features__words_not_stopword__standard__with_std', 'features__avg_word_length__memory', 'features__avg_word_length__steps', 'features__avg_word_length__verbose', 'features__avg_word_length__selector', 'features__avg_word_length__standard', 'features__avg_word_length__selector__key', 'features__avg_word_length__standard__copy', 'features__avg_word_length__standard__with_mean', 'features__avg_word_length__standard__with_std', 'features__commas__memory', 'features__commas__steps', 'features__commas__verbose', 'features__commas__selector', 'features__commas__standard', 'features__commas__selector__key', 'features__commas__standard__copy', 'features__commas__standard__with_mean', 'features__commas__standard__with_std', 'classifier__bootstrap', 'classifier__class_weight', 'classifier__criterion', 'classifier__max_depth', 'classifier__max_features', 'classifier__max_leaf_nodes', 'classifier__min_impurity_decrease', 'classifier__min_impurity_split', 'classifier__min_samples_leaf', 'classifier__min_samples_split', 'classifier__min_weight_fraction_leaf', 'classifier__n_estimators', 'classifier__n_jobs', 'classifier__oob_score', 'classifier__random_state', 'classifier__verbose', 'classifier__warm_start'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmTHaDIDe0dH",
        "colab_type": "text"
      },
      "source": [
        "这些都是pipeline相关的属性，即超参数，这些超参数的组合变化，超参数的数值变化都会影响一个pipeline好不好用。在此只为展示操作，因此随心情挑选四个超参数进行调优。优化方式为GridSearchCV，即 网格搜索交叉验证法，适用于少量的超参数个数和少量的数值候选调优。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODjaXgV4e9v3",
        "colab_type": "code",
        "outputId": "d4734bd4-e8e9-42c5-ca02-011ba46df890",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        }
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "hyperparameters = { 'features__text__tfidf__max_df': [0.9, 0.95],\n",
        "                    'features__text__tfidf__ngram_range': [(1,1), (1,2)],\n",
        "                   'classifier__max_depth': [50, 70],\n",
        "                    'classifier__min_samples_leaf': [1,2]\n",
        "                  }\n",
        "clf = GridSearchCV(pipeline, hyperparameters, cv=5)\n",
        " \n",
        "# Fit and tune model\n",
        "clf.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('features',\n",
              "                                        FeatureUnion(n_jobs=None,\n",
              "                                                     transformer_list=[('text',\n",
              "                                                                        Pipeline(memory=None,\n",
              "                                                                                 steps=[('selector',\n",
              "                                                                                         TextSelector(key='processed')),\n",
              "                                                                                        ('tfidf',\n",
              "                                                                                         TfidfVectorizer(analyzer='word',\n",
              "                                                                                                         binary=False,\n",
              "                                                                                                         decode_error='strict',\n",
              "                                                                                                         dtype=<class 'numpy.float64'>,\n",
              "                                                                                                         encoding='utf-8',\n",
              "                                                                                                         input=...\n",
              "                                                               oob_score=False,\n",
              "                                                               random_state=42,\n",
              "                                                               verbose=0,\n",
              "                                                               warm_start=False))],\n",
              "                                verbose=False),\n",
              "             iid='warn', n_jobs=None,\n",
              "             param_grid={'classifier__max_depth': [50, 70],\n",
              "                         'classifier__min_samples_leaf': [1, 2],\n",
              "                         'features__text__tfidf__max_df': [0.9, 0.95],\n",
              "                         'features__text__tfidf__ngram_range': [(1, 1),\n",
              "                                                                (1, 2)]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDn3WN7EfMY4",
        "colab_type": "text"
      },
      "source": [
        "观察调优结果，即超参数最终选择的数值为多少，输入："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXHDKrMYenFM",
        "colab_type": "code",
        "outputId": "8e9a98da-ab5c-4412-dfc2-a04df1ffa789",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "clf.best_params_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'classifier__max_depth': 70,\n",
              " 'classifier__min_samples_leaf': 2,\n",
              " 'features__text__tfidf__max_df': 0.9,\n",
              " 'features__text__tfidf__ngram_range': (1, 1)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KhY5aybfYUN",
        "colab_type": "text"
      },
      "source": [
        "隐藏菜单操作为调用 refit，可自动使用使用pipeline来fit所有的训练数据。并将其应用于测试集。\n",
        "\n",
        "输入："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyXZ35Umem8E",
        "colab_type": "code",
        "outputId": "bef37ade-ec28-44aa-9825-18165d5d7051",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#refitting on entire training data using best settings\n",
        "clf.refit\n",
        "\n",
        "preds = clf.predict(X_test)\n",
        "probs = clf.predict_proba(X_test)\n",
        "\n",
        "np.mean(preds == y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6425255338904364"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkOfkhabffM5",
        "colab_type": "text"
      },
      "source": [
        "还是有一点精度的提高的。\n",
        "\n",
        "进行预测\n",
        "\n",
        "做模型总要有结果的，最后对数据集进行predict，看看未知文本到底是哪位作者写出来的概率更大。\n",
        "\n",
        "输入："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rnYosRafkTC",
        "colab_type": "code",
        "outputId": "4a4f0a79-48be-4148-ada4-9633f0b224d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "submission = pd.read_csv('test.csv')\n",
        "\n",
        "#preprocessing\n",
        "submission = processing(submission)\n",
        "predictions = clf.predict_proba(submission)\n",
        "\n",
        "preds = pd.DataFrame(data=predictions, columns = clf.best_estimator_.named_steps['classifier'].classes_)\n",
        "\n",
        "#generating a submission file\n",
        "result = pd.concat([submission[['id']], preds], axis=1)\n",
        "result.set_index('id', inplace = True)\n",
        "result.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>EAP</th>\n",
              "      <th>HPL</th>\n",
              "      <th>MWS</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>id02310</th>\n",
              "      <td>0.308413</td>\n",
              "      <td>0.278221</td>\n",
              "      <td>0.413366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id24541</th>\n",
              "      <td>0.636757</td>\n",
              "      <td>0.161106</td>\n",
              "      <td>0.202137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id00134</th>\n",
              "      <td>0.328440</td>\n",
              "      <td>0.449705</td>\n",
              "      <td>0.221855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id27757</th>\n",
              "      <td>0.647944</td>\n",
              "      <td>0.167825</td>\n",
              "      <td>0.184231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id04081</th>\n",
              "      <td>0.528074</td>\n",
              "      <td>0.206907</td>\n",
              "      <td>0.265020</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              EAP       HPL       MWS\n",
              "id                                   \n",
              "id02310  0.308413  0.278221  0.413366\n",
              "id24541  0.636757  0.161106  0.202137\n",
              "id00134  0.328440  0.449705  0.221855\n",
              "id27757  0.647944  0.167825  0.184231\n",
              "id04081  0.528074  0.206907  0.265020"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_z7Mwwdf0oX",
        "colab_type": "text"
      },
      "source": [
        "Pipeline 总结\n",
        "\n",
        "sklean提供的pipeline来将多个学习器组成流水线，通常流水线的形式为：\n",
        "\n",
        "将数据标准化的学习器—-特征提取的学习器—-执行预测的学习器/分类器\n",
        "\n",
        "除了最后一个学习器之外，前面的所有学习器必须提供transform方法，该方法用于数据转\n",
        "\n",
        "（例如： 归一化，正则化，以及特征提取）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Qr07c2MfkGG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4khMtF8fkNG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AxbfKIfYSvK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhHn3qRicde1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxuK0bC1cdZ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPZpvXiwcdUK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1eB41eScfPo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXv4ZjL-cfLx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOuDdTt3cfH9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GZwY35ucoA_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cog3Vx4ecn9s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_j6WyZ7ecn6E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nA3a_hT5cn1y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}