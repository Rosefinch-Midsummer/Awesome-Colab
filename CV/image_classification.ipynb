{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "image_classification.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rosefinch-Midsummer/Awesome-Colab/blob/master/CV/image_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMh4yXXZXCUr",
        "colab_type": "text"
      },
      "source": [
        "[来源](https://colab.research.google.com/github/google/eng-edu/blob/master/ml/pc/exercises/image_classification_part3.ipynb)\n",
        "\n",
        "In Exercise 1, we built a convnet from scratch, and were able to achieve an accuracy of about 70%. With the addition of data augmentation and dropout in Exercise 2, we were able to increase accuracy to about 80%. That seems decent, but 20% is still too high of an error rate. Maybe we just don't have enough training data available to properly solve the problem. What other approaches can we try?\n",
        "\n",
        "In this exercise, we'll look at two techniques for repurposing feature data generated from image models that have already been trained on large sets of data, feature extraction and fine tuning, and use them to improve the accuracy of our cat vs. dog classification model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1xJZ5glPPCRz",
        "outputId": "c84bd88a-b70e-433e-98cd-6fc942727a22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        }
      },
      "source": [
        "import os\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7j6bHmeZKkF",
        "colab_type": "text"
      },
      "source": [
        "下载权重"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KMrbllgAFipZ",
        "outputId": "6e2a14c1-27b4-4ed8-dd36-8c46c37e96ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-18 12:21:32--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 66.102.1.128, 2a00:1450:400c:c00::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|66.102.1.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "\r          /tmp/ince   0%[                    ]       0  --.-KB/s               \r         /tmp/incep  12%[=>                  ]  10.51M  52.5MB/s               \r        /tmp/incept  38%[======>             ]  32.01M  62.6MB/s               \r       /tmp/incepti  85%[================>   ]  72.01M  98.8MB/s               \r/tmp/inception_v3_w 100%[===================>]  83.84M   108MB/s    in 0.8s    \n",
            "\n",
            "2019-11-18 12:21:33 (108 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RS1BHTqUKAT",
        "colab_type": "code",
        "outputId": "f2143d4c-11f7-4507-c65e-bae56d8b407b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "pre_trained_model = InceptionV3(\n",
        "    input_shape=(150, 150, 3), include_top=False, weights=None)\n",
        "pre_trained_model.load_weights(local_weights_file)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWD-rkjpZ-Pr",
        "colab_type": "text"
      },
      "source": [
        "By specifying the include_top=False argument, we load a network that doesn't include the classification layers at the top—ideal for feature extraction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "a38rB3lyedcB",
        "colab": {}
      },
      "source": [
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XGBGDiOAepnO"
      },
      "source": [
        "The layer we will use for feature extraction in Inception v3 is called `mixed7`. It is not the bottleneck of the network, but we are using it to keep a sufficiently large feature map (7x7 in this case). (Using the bottleneck layer would have resulting in a 3x3 feature map, which is a bit small.) Let's get the output from `mixed7`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMtog_PBUKtO",
        "colab_type": "code",
        "outputId": "833af8fe-e475-457f-d60d-fa082da2e6c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape:', last_layer.output_shape)\n",
        "last_output = last_layer.output"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "last layer output shape: (None, 7, 7, 768)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMqvcax1ca7d",
        "colab_type": "text"
      },
      "source": [
        "Now let's stick a fully connected classifier on top of last_output:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWiKmwkwUK-V",
        "colab_type": "code",
        "outputId": "166b39a0-69c6-49e1-b1db-47832e8c57af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)\n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "# Configure and compile the model\n",
        "model = Model(pre_trained_model.input, x)\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=RMSprop(lr=0.0001),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqx_ZbFNcvKq",
        "colab_type": "text"
      },
      "source": [
        "NOTE: The 2,000 images used in this exercise are excerpted from the \"Dogs vs. Cats\" dataset available on Kaggle, which contains 25,000 images. Here, we use a subset of the full dataset to decrease training time for educational purposes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHklI8ijUKog",
        "colab_type": "code",
        "outputId": "f16901a5-bc91-4a84-ac13-7e207327e1c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "   https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip -O \\\n",
        "   /tmp/cats_and_dogs_filtered.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-18 12:21:51--  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.15.128, 2a00:1450:400c:c07::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.15.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 68606236 (65M) [application/zip]\n",
            "Saving to: ‘/tmp/cats_and_dogs_filtered.zip’\n",
            "\n",
            "\r          /tmp/cats   0%[                    ]       0  --.-KB/s               \r         /tmp/cats_  33%[=====>              ]  22.20M   111MB/s               \r        /tmp/cats_a  96%[==================> ]  63.27M   158MB/s               \r/tmp/cats_and_dogs_ 100%[===================>]  65.43M   161MB/s    in 0.4s    \n",
            "\n",
            "2019-11-18 12:21:51 (161 MB/s) - ‘/tmp/cats_and_dogs_filtered.zip’ saved [68606236/68606236]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qTnE_8ZczK8",
        "colab_type": "code",
        "outputId": "1d4c8f46-1d64-413b-d9f9-e7c12a3262c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "local_zip = '/tmp/cats_and_dogs_filtered.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()\n",
        "\n",
        "# Define our example directories and files\n",
        "base_dir = '/tmp/cats_and_dogs_filtered'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "\n",
        "# Directory with our training cat pictures\n",
        "train_cats_dir = os.path.join(train_dir, 'cats')\n",
        "\n",
        "# Directory with our training dog pictures\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
        "\n",
        "# Directory with our validation cat pictures\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
        "\n",
        "# Directory with our validation dog pictures\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
        "\n",
        "train_cat_fnames = os.listdir(train_cats_dir)\n",
        "train_dog_fnames = os.listdir(train_dogs_dir)\n",
        "\n",
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir, # This is the source directory for training images\n",
        "        target_size=(150, 150),  # All images will be resized to 150x150\n",
        "        batch_size=20,\n",
        "        # Since we use binary_crossentropy loss, we need binary labels\n",
        "        class_mode='binary')\n",
        "\n",
        "# Flow validation images in batches of 20 using val_datagen generator\n",
        "validation_generator = val_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=20,\n",
        "        class_mode='binary')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjdyyWihdOXx",
        "colab_type": "text"
      },
      "source": [
        "Finally, let's train the model using the features we extracted. We'll train on all 2000 images available, for 2 epochs, and validate on all 1,000 validation images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ef4LzcxZczaN",
        "colab_type": "code",
        "outputId": "a3944ba5-c501-4e2a-e539-1295648b36fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch=100,\n",
        "      epochs=2,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=50,\n",
        "      verbose=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "Epoch 1/2\n",
            "100/100 - 30s - loss: 0.4929 - acc: 0.7685 - val_loss: 0.3703 - val_acc: 0.8870\n",
            "Epoch 2/2\n",
            "Epoch 1/2\n",
            "100/100 - 22s - loss: 0.3860 - acc: 0.8310 - val_loss: 0.1996 - val_acc: 0.9480\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjvliRz4d7MH",
        "colab_type": "text"
      },
      "source": [
        "# Further Improving Accuracy with Fine-Tuning\n",
        "In our feature-extraction experiment, we only tried adding two classification layers on top of an Inception V3 layer. The weights of the pretrained network were not updated during training. One way to increase performance even further is to \"fine-tune\" the weights of the top layers of the pretrained model alongside the training of the top-level classifier. A couple of important notes on fine-tuning:\n",
        "\n",
        "- Fine-tuning should only be attempted after you have trained the top-level classifier with the pretrained model set to non-trainable. If you add a randomly initialized classifier on top of a pretrained model and attempt to train all layers jointly, the magnitude of the gradient updates will be too large (due to the random weights from the classifier), and your pretrained model will just forget everything it has learned.\n",
        "- Additionally, we fine-tune only the top layers of the pre-trained model rather than all layers of the pretrained model because, in a convnet, the higher up a layer is, the more specialized it is. The first few layers in a convnet learn very simple and generic features, which generalize to almost all types of images. But as you go higher up, the features are increasingly specific to the dataset that the model is trained on. The goal of fine-tuning is to adapt these specialized features to work with the new dataset.\n",
        "\n",
        "All we need to do to implement fine-tuning is to set the top layers of Inception V3 to be trainable, recompile the model (necessary for these changes to take effect), and resume training. Let's unfreeze all layers belonging to the mixed7 module—i.e., all layers found after mixed6—and recompile the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ij1r7qbHcz1H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "unfreeze = False\n",
        "\n",
        "# Unfreeze all models after \"mixed6\"\n",
        "for layer in pre_trained_model.layers:\n",
        "  if unfreeze:\n",
        "    layer.trainable = True\n",
        "  if layer.name == 'mixed6':\n",
        "    unfreeze = True\n",
        "\n",
        "# As an optimizer, here we will use SGD \n",
        "# with a very low learning rate (0.00001)\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=SGD(\n",
        "                  lr=0.00001, \n",
        "                  momentum=0.9),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ndFlz32gJyl",
        "colab_type": "text"
      },
      "source": [
        "Now let's retrain the model. We'll train on all 2000 images available, for 50 epochs, and validate on all 1,000 validation images. (This may take 15-20 minutes to run.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjUAzrhgczx1",
        "colab_type": "code",
        "outputId": "44715305-9738-42cb-a5bb-13b505704555",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch=100,\n",
        "      epochs=50,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=50,\n",
        "      verbose=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "Epoch 1/50\n",
            "100/100 - 27s - loss: 0.3183 - acc: 0.8535 - val_loss: 0.2276 - val_acc: 0.9410\n",
            "Epoch 2/50\n",
            "Epoch 1/50\n",
            "100/100 - 21s - loss: 0.2957 - acc: 0.8670 - val_loss: 0.2446 - val_acc: 0.9380\n",
            "Epoch 3/50\n",
            "Epoch 1/50\n",
            "100/100 - 21s - loss: 0.2862 - acc: 0.8695 - val_loss: 0.2580 - val_acc: 0.9340\n",
            "Epoch 4/50\n",
            "Epoch 1/50\n",
            "100/100 - 21s - loss: 0.2916 - acc: 0.8765 - val_loss: 0.2629 - val_acc: 0.9350\n",
            "Epoch 5/50\n",
            "Epoch 1/50\n",
            "100/100 - 21s - loss: 0.2848 - acc: 0.8735 - val_loss: 0.2647 - val_acc: 0.9340\n",
            "Epoch 6/50\n",
            "Epoch 1/50\n",
            "100/100 - 21s - loss: 0.2785 - acc: 0.8780 - val_loss: 0.2680 - val_acc: 0.9360\n",
            "Epoch 7/50\n",
            "Epoch 1/50\n",
            "100/100 - 21s - loss: 0.2871 - acc: 0.8805 - val_loss: 0.2717 - val_acc: 0.9360\n",
            "Epoch 8/50\n",
            "Epoch 1/50\n",
            "100/100 - 21s - loss: 0.2882 - acc: 0.8705 - val_loss: 0.2717 - val_acc: 0.9350\n",
            "Epoch 9/50\n",
            "Epoch 1/50\n",
            "100/100 - 21s - loss: 0.2926 - acc: 0.8720 - val_loss: 0.2698 - val_acc: 0.9360\n",
            "Epoch 10/50\n",
            "Epoch 1/50\n",
            "100/100 - 22s - loss: 0.2725 - acc: 0.8715 - val_loss: 0.2694 - val_acc: 0.9360\n",
            "Epoch 11/50\n",
            "Epoch 1/50\n",
            "100/100 - 22s - loss: 0.2869 - acc: 0.8715 - val_loss: 0.2708 - val_acc: 0.9360\n",
            "Epoch 12/50\n",
            "Epoch 1/50\n",
            "100/100 - 22s - loss: 0.2823 - acc: 0.8695 - val_loss: 0.2723 - val_acc: 0.9360\n",
            "Epoch 13/50\n",
            "Epoch 1/50\n",
            "100/100 - 23s - loss: 0.2932 - acc: 0.8705 - val_loss: 0.2679 - val_acc: 0.9360\n",
            "Epoch 14/50\n",
            "Epoch 1/50\n",
            "100/100 - 22s - loss: 0.2818 - acc: 0.8730 - val_loss: 0.2682 - val_acc: 0.9360\n",
            "Epoch 15/50\n",
            "Epoch 1/50\n",
            "100/100 - 23s - loss: 0.2792 - acc: 0.8805 - val_loss: 0.2709 - val_acc: 0.9370\n",
            "Epoch 16/50\n",
            "Epoch 1/50\n",
            "100/100 - 22s - loss: 0.2894 - acc: 0.8685 - val_loss: 0.2690 - val_acc: 0.9370\n",
            "Epoch 17/50\n",
            "Epoch 1/50\n",
            "100/100 - 22s - loss: 0.2834 - acc: 0.8795 - val_loss: 0.2691 - val_acc: 0.9360\n",
            "Epoch 18/50\n",
            "Epoch 1/50\n",
            "100/100 - 22s - loss: 0.2823 - acc: 0.8780 - val_loss: 0.2638 - val_acc: 0.9340\n",
            "Epoch 19/50\n",
            "Epoch 1/50\n",
            "100/100 - 22s - loss: 0.2866 - acc: 0.8840 - val_loss: 0.2659 - val_acc: 0.9360\n",
            "Epoch 20/50\n",
            "Epoch 1/50\n",
            "100/100 - 22s - loss: 0.2941 - acc: 0.8765 - val_loss: 0.2687 - val_acc: 0.9370\n",
            "Epoch 21/50\n",
            "Epoch 1/50\n",
            "100/100 - 22s - loss: 0.2771 - acc: 0.8815 - val_loss: 0.2674 - val_acc: 0.9360\n",
            "Epoch 22/50\n",
            "Epoch 1/50\n",
            "100/100 - 22s - loss: 0.2742 - acc: 0.8845 - val_loss: 0.2666 - val_acc: 0.9360\n",
            "Epoch 23/50\n",
            "Epoch 1/50\n",
            "100/100 - 22s - loss: 0.2639 - acc: 0.8875 - val_loss: 0.2672 - val_acc: 0.9370\n",
            "Epoch 24/50\n",
            "Epoch 1/50\n",
            "100/100 - 22s - loss: 0.2801 - acc: 0.8780 - val_loss: 0.2687 - val_acc: 0.9370\n",
            "Epoch 25/50\n",
            "Epoch 1/50\n",
            "100/100 - 22s - loss: 0.2760 - acc: 0.8730 - val_loss: 0.2648 - val_acc: 0.9370\n",
            "Epoch 26/50\n",
            "Epoch 1/50\n",
            "100/100 - 22s - loss: 0.2718 - acc: 0.8800 - val_loss: 0.2715 - val_acc: 0.9370\n",
            "Epoch 27/50\n",
            "Epoch 1/50\n",
            "100/100 - 22s - loss: 0.2995 - acc: 0.8685 - val_loss: 0.2647 - val_acc: 0.9360\n",
            "Epoch 28/50\n",
            "Epoch 1/50\n",
            "100/100 - 22s - loss: 0.2744 - acc: 0.8835 - val_loss: 0.2638 - val_acc: 0.9350\n",
            "Epoch 29/50\n",
            "Epoch 1/50\n",
            "100/100 - 22s - loss: 0.2617 - acc: 0.8855 - val_loss: 0.2655 - val_acc: 0.9360\n",
            "Epoch 30/50\n",
            "Epoch 1/50\n",
            "100/100 - 22s - loss: 0.2652 - acc: 0.8795 - val_loss: 0.2662 - val_acc: 0.9370\n",
            "Epoch 31/50\n",
            "Epoch 1/50\n",
            "100/100 - 22s - loss: 0.2824 - acc: 0.8690 - val_loss: 0.2692 - val_acc: 0.9370\n",
            "Epoch 32/50\n",
            "Epoch 1/50\n",
            "100/100 - 22s - loss: 0.2721 - acc: 0.8775 - val_loss: 0.2689 - val_acc: 0.9360\n",
            "Epoch 33/50\n",
            "Epoch 1/50\n",
            "100/100 - 22s - loss: 0.2758 - acc: 0.8745 - val_loss: 0.2626 - val_acc: 0.9370\n",
            "Epoch 34/50\n",
            "Epoch 1/50\n",
            "100/100 - 22s - loss: 0.2745 - acc: 0.8845 - val_loss: 0.2659 - val_acc: 0.9370\n",
            "Epoch 35/50\n",
            "Epoch 1/50\n",
            "100/100 - 22s - loss: 0.2928 - acc: 0.8720 - val_loss: 0.2694 - val_acc: 0.9370\n",
            "Epoch 36/50\n",
            "Epoch 1/50\n",
            "100/100 - 22s - loss: 0.2696 - acc: 0.8810 - val_loss: 0.2636 - val_acc: 0.9360\n",
            "Epoch 37/50\n",
            "Epoch 1/50\n",
            "100/100 - 22s - loss: 0.2663 - acc: 0.8905 - val_loss: 0.2632 - val_acc: 0.9370\n",
            "Epoch 38/50\n",
            "Epoch 1/50\n",
            "100/100 - 22s - loss: 0.2670 - acc: 0.8900 - val_loss: 0.2618 - val_acc: 0.9360\n",
            "Epoch 39/50\n",
            "Epoch 1/50\n",
            "100/100 - 22s - loss: 0.2949 - acc: 0.8710 - val_loss: 0.2622 - val_acc: 0.9370\n",
            "Epoch 40/50\n",
            "Epoch 1/50\n",
            "100/100 - 22s - loss: 0.2854 - acc: 0.8770 - val_loss: 0.2608 - val_acc: 0.9370\n",
            "Epoch 41/50\n",
            "Epoch 1/50\n",
            "100/100 - 22s - loss: 0.2687 - acc: 0.8840 - val_loss: 0.2605 - val_acc: 0.9380\n",
            "Epoch 42/50\n",
            "Epoch 1/50\n",
            "100/100 - 22s - loss: 0.2859 - acc: 0.8715 - val_loss: 0.2619 - val_acc: 0.9370\n",
            "Epoch 43/50\n",
            "Epoch 1/50\n",
            "100/100 - 22s - loss: 0.2750 - acc: 0.8810 - val_loss: 0.2560 - val_acc: 0.9380\n",
            "Epoch 44/50\n",
            "Epoch 1/50\n",
            "100/100 - 22s - loss: 0.2713 - acc: 0.8865 - val_loss: 0.2599 - val_acc: 0.9370\n",
            "Epoch 45/50\n",
            "Epoch 1/50\n",
            "100/100 - 22s - loss: 0.2719 - acc: 0.8845 - val_loss: 0.2575 - val_acc: 0.9380\n",
            "Epoch 46/50\n",
            "Epoch 1/50\n",
            "100/100 - 22s - loss: 0.2879 - acc: 0.8765 - val_loss: 0.2606 - val_acc: 0.9380\n",
            "Epoch 47/50\n",
            "Epoch 1/50\n",
            "100/100 - 23s - loss: 0.2620 - acc: 0.8895 - val_loss: 0.2595 - val_acc: 0.9380\n",
            "Epoch 48/50\n",
            "Epoch 1/50\n",
            "100/100 - 22s - loss: 0.2594 - acc: 0.8855 - val_loss: 0.2611 - val_acc: 0.9390\n",
            "Epoch 49/50\n",
            "Epoch 1/50\n",
            "100/100 - 22s - loss: 0.2533 - acc: 0.8875 - val_loss: 0.2590 - val_acc: 0.9380\n",
            "Epoch 50/50\n",
            "Epoch 1/50\n",
            "100/100 - 22s - loss: 0.2636 - acc: 0.8845 - val_loss: 0.2603 - val_acc: 0.9390\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDQVttvMgRMA",
        "colab_type": "text"
      },
      "source": [
        "We are seeing a nice improvement, with the validation loss going from ~1.7 down to ~1.2, and accuracy going from 88% to 92%. That's a 4.5% relative improvement in accuracy.\n",
        "\n",
        "Let's plot the training and validation loss and accuracy to show it conclusively:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GzrYNgSgRlQ",
        "colab_type": "code",
        "outputId": "18d78d02-49d4-475d-b8fa-52c4fe7494fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        }
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "# Retrieve a list of accuracy results on training and validation data\n",
        "# sets for each training epoch\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "\n",
        "# Retrieve a list of list results on training and validation data\n",
        "# sets for each training epoch\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "# Get number of epochs\n",
        "epochs = range(len(acc))\n",
        "\n",
        "# Plot training and validation accuracy per epoch\n",
        "plt.plot(epochs, acc)\n",
        "plt.plot(epochs, val_acc)\n",
        "plt.title('Training and validation accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "# Plot training and validation loss per epoch\n",
        "plt.plot(epochs, loss)\n",
        "plt.plot(epochs, val_loss)\n",
        "plt.title('Training and validation loss')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Training and validation loss')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FetNmPdpgR8v",
        "colab_type": "text"
      },
      "source": [
        "Congratulations! Using feature extraction and fine-tuning, you've built an image classification model that can identify cats vs. dogs in images with over 90% accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CV6jaysk4TS",
        "colab_type": "code",
        "outputId": "a62f58d8-bf34-4967-85cd-00b16ddd383b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 37632)        0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1024)         38536192    flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 1024)         0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            1025        dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 47,512,481\n",
            "Trainable params: 40,677,249\n",
            "Non-trainable params: 6,835,232\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AawgOO9g2Es",
        "colab_type": "text"
      },
      "source": [
        "#Clean Up\n",
        "Run the following cell to terminate the kernel and free memory resources:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJo5spWYgST-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os, signal\n",
        "os.kill(os.getpid(), signal.SIGKILL)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}